contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()
library(tidybayes)
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.89,
re_formula = NA) |>
contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.89,
re_formula = NA) |>
contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
xlab(expression(beta ~""["reward (only story)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
model |>
emmeans(~ reward_oneback,
at = list(condition = 'abstract'),
epred = T,
level = 0.89,
re_formula = NA) |>
contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
xlab(expression(beta ~""["reward (only story)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
params = insight::get_parameters(model)
names(params)
data.frame(x = params[,'b_reward_onebackrewarded:conditionstory'])|>
ggplot(aes(x = x)) +
stat_halfeye() +
xlab(expression(beta ~""["reward X mapping_switch X condition"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
data.frame(x = params[,'b_reward_onebackrewarded:conditionstory'])|>
ggplot(aes(x = x)) +
stat_halfeye() +
xlab(expression(beta ~""["reward X condition"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
model |>
emmeans(~ reward_oneback,
at = list(condition = 'abstract'),
epred = T,
level = 0.89,
re_formula = NA) |>
contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
xlab(expression(beta ~""["reward (only abstract)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
f_model = stay_key2 ~ reward_oneback*condition + (reward_oneback | participant)
get_prior(f_model, data = df |> filter(!state2_repeat), family = bernoulli("logit"))
myprior = brms::prior(normal(0, 4), class = b)
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
get_prior(model)
prior_summary(model)
myprior = brms::prior(normal(0, 4), class = b)
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
prior_summary(model)
myprior = prior(normal(0, 4), class = b) +
prior(normal(0, 5), class = Intercept)
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
prior_summary(model)
myprior = c(prior(normal(0, 4), class = b),
prior(normal(0, 5), class = Intercept))
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
prior_summary(model)
myprior = prior(normal(0, 50), class = b)
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
prior_summary(model)
myprior
rm(list=ls())
df = read.csv('./fmri_magic_carpet-main/fmri_magic_carpet-main/code/analysis/beh_noslow.csv')
names(df)
library(dplyr)
df =
df |>
mutate(reward        = factor(reward, levels = c(0,1), labels = c("unrewarded", "rewarded")),
reward_oneback = lag(reward),
transition         = factor(common, levels = c(0,1), labels = c("rare", "common")),
transition_oneback = lag(transition),
state2 = final_state,
mapping_state1 = isymbol_lft,
mapping_state2 = fsymbol_lft,
key1 = (choice1==isymbol_lft)*1, #1 for left, 0 for right
key2 = (choice2==fsymbol_lft)*1, #1 for left, 0 for right
stay_ch1       = lag(choice1)==choice1,
stay_ch2       = lag(choice2)==choice2,
stay_key1      = (lag(key1)==key1)*1,
stay_key2      = (lag(key2)==key2)*1,
stay_key2_to_1 = (lag(key2)==key1)*1, #check coding!!
state2_repeat  = (lag(state2) == state2),
state2_mapping_repeat = mapping_state2 == lag(mapping_state2)
)
#### stay ~ reward X transition ----
df |>
group_by(condition,
transition_oneback,
reward_oneback) |>
summarise(mean(stay_ch1))
##### stay_key2 ~ reward -----
df |>
filter(!state2_repeat) |>
group_by(condition,
reward_oneback) |>
summarise(mean(stay_key2))
library(brms)
f_model = stay_key2 ~ reward_oneback*condition + (reward_oneback | participant)
get_prior(f_model, data = df |> filter(!state2_repeat), family = bernoulli("logit"))
myprior = prior(normal(0, 50), class = b)
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
prior_summary(model)
prior_summary(model_compile)
myprior = prior(normal(0, 5), class = b)+
prior(normal(0, 5), class = Intercept)
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
prior_summary(model_compile)
myprior = prior(normal(0, 4), class = b)+
prior(normal(0, 5), class = Intercept)
#compile
model_compile = brm(f_model, data = df |> filter(!state2_repeat) ,chains = 0,
family = bernoulli("logit"),
prior = myprior, backend='cmdstan')
prior_summary(model_compile)
#examine your model
load(file='./stay_key2 ~ reward_onebackXcondition.rdata')
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
brms::plot(fit, variable = "^b_", regex = TRUE)
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
brms::plot(model, variable = "^b_", regex = TRUE)
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
plot(model, variable = "^b_", regex = TRUE)
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
plot(model, variable = "^b_", regex = TRUE, theme = xlim(-0.5,0.5))
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
plot(model, variable = "^b_", regex = TRUE, theme =   stat_halfeye()+
xlab(expression(beta ~""["reward (only abstract)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density'))
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
plot(model, variable = "^b_", regex = TRUE, theme =
xlab(expression(beta ~""["reward (only abstract)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density'))
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
plot(model, variable = "^b_", regex = TRUE, theme =  xlab(expression(beta ~""["reward (only abstract)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density'))
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
plot(model, variable = "^b_", regex = TRUE, theme =  xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density'))
##save(model,file='./stay_key2 ~ reward_onebackXcondition.rdata')
plot(model, variable = "^b_", regex = TRUE)[[1]]
rm(list=ls())
df = read.csv('./fmri_magic_carpet-main/fmri_magic_carpet-main/code/analysis/beh_noslow.csv')
names(df)
library(dplyr)
df =
df |>
mutate(reward        = factor(reward, levels = c(0,1), labels = c("unrewarded", "rewarded")),
reward_oneback = lag(reward),
transition         = factor(common, levels = c(0,1), labels = c("rare", "common")),
transition_oneback = lag(transition),
state2 = final_state,
mapping_state1 = isymbol_lft,
mapping_state2 = fsymbol_lft,
key1 = (choice1==isymbol_lft)*1, #1 for left, 0 for right
key2 = (choice2==fsymbol_lft)*1, #1 for left, 0 for right
stay_ch1       = lag(choice1)==choice1,
stay_ch2       = lag(choice2)==choice2,
stay_key1      = (lag(key1)==key1)*1,
stay_key2      = (lag(key2)==key2)*1,
stay_key2_to_1 = (lag(key2)==key1)*1, #check coding!!
state2_repeat  = (lag(state2) == state2),
state2_mapping_repeat = mapping_state2 == lag(mapping_state2)
)
#examine your model
load(file='./stay_key2 ~ reward_onebackXcondition.rdata')
#contrasts
library(tidybayes)
model |>
emmeans(~ reward_oneback,
epred = T,
level = 0.90,
re_formula = NA)
#contrasts
library(tidybayes)
model |>
emmeans(~ reward_oneback,
epred = T,
level = 0.90,
re_formula = NA)
library(emmeans)
model |>
emmeans(~ reward_oneback,
epred = T,
level = 0.90,
re_formula = NA)
library(emmeans)
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise')|>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()
#plot posterior
library(ggdist)
library(ggplot2)
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise')|>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise')
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise')|>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
theme_classic()
model |>
emmeans(~ reward_oneback,
at = list(condition = 'abstract'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise')|>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
theme_classic()
params = insight::get_parameters(model)
names(params)
data.frame(x = params[,'b_reward_onebackrewarded:conditionstory'])|>
ggplot(aes(x = x)) +
stat_halfeye() +
xlab(expression(beta ~""["reward X condition"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
model |>
emmeans(~ reward_oneback,
at = list(condition = 'abstract'),
epred = T,
level = 0.89,
re_formula = NA) |>
contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
xlab(expression(beta ~""["reward (only abstract)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.89,
re_formula = NA) |>
contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
xlab(expression(beta ~""["reward (only story)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
#examine your model
load('./stay_key2_to_1 ~ reward_onebackXcondition.rdata')
bayestestR::describe_posterior(model, rope_range = c(-0.1,+0.1))
brms::conditional_effects(model)
library(ggplot2)
library(emmeans)
library(tidybayes)
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
xlab(expression(beta ~""["reward (only story)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
bayestestR::describe_posterior(model, rope_range = c(-0.1,+0.1))
brms::conditional_effects(model)
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA)
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise')
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'pairwise',reverse = TRUE)
model |>
emmeans(~ reward_oneback,
at = list(condition = 'story'),
epred = T,
level = 0.90,
re_formula = NA) |>
contrast(method = 'revpairwise') |>
gather_emmeans_draws()|>
ggplot(aes(x=.value))+
stat_halfeye()+
xlab(expression(beta ~""["reward (only story)"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
params = insight::get_parameters(model)
names(params)
data.frame(x = params[,'b_reward_onebackrewarded:conditionstory'])|>
ggplot(aes(x = x)) +
stat_halfeye() +
xlab(expression(beta ~""["reward X condition"])) +
xlim(-0.5,0.5)+
ggtitle("")+
theme_classic()+
theme(axis.text.y  = element_blank(),
axis.ticks.y = element_blank())+
ylab('density')
#population parameters
Nsubjects = 100
#population parameters
Nsubjects = 100
b0 = 0
b1 = 0.4
#generate data
height = rnorm(Nsubjects, mean = 170, sd = 20)
mu     = b0 + b1*height
sigma  = 15
weight = rnorm(Nsubjects, mean = mu, sd = sigma)
#visual inspection
plot(height, weight)
#visual inspection
plot(height, weight)
#recover b0, b1 and sigma
f_model = weight ~ 1 + height
#recover b0, b1 and sigma
library(brms)
df = data.frame(weight = weight, height = height),
df = data.frame(weight = weight, height = height)
View(df)
f_model = weight ~ 1 + height
get_prior(f_model,df)
get_prior(f_model,df)
model = brms::brm(f_model,
data = df,
chain = 4,
cores = 4,
warmup = 2000,
iter   = 4000,
backend = 'cmdstanr')
model
plot(model)
describe_posterior(model)
bayestestr::describe_posterior(model)
bayestestR::describe_posterior(model)
bayestestR::describe_posterior(model, rope_range = c(-.001,+0.001))
bayestestR::describe_posterior(model, rope_range = c(-.01,+0.01))
bayestestR::describe_posterior(model, rope_range = c(-.1,+0.1))
bayestestR::describe_posterior(model, rope_range = c(-.1,+.1))
myprior = prior(normal(0,50), class = b)
get_prior(f_model,df, prior = myprior)
model = brms::brm(f_model,
data = df,
chain = 4,
cores = 4,
warmup = 2000,
iter   = 4000,
prior = myprior,
backend = 'cmdstanr')
prior_summary(model)
bayestestR::describe_posterior(model, rope_range = c(-.1,+.1))
myprior = prior(normal(0,0.0001), class = b)
model = brms::brm(f_model,
data = df,
chain = 4,
cores = 4,
warmup = 2000,
iter   = 4000,
prior = myprior,
backend = 'cmdstanr')
prior_summary(model)
plot(model)
bayestestR::describe_posterior(model, rope_range = c(-.1,+.1))
